
"""
SPECIAL CLASS TO MANAGE VULNERABILITY FROM MODPATH PARTICLE TRACKING
"""

import os
import numpy as np
import pandas as pd
import matplotlib as mpl
import matplotlib.pyplot as plt
from matplotlib_venn import venn2, venn3, venn2_circles, venn3_circles
import shapely
from shapely.geometry import *
shapely.speedups.disable()
from flopy.modpath import ParticleData, ParticleGroup
from flopy.utils import EndpointFile, PathlineFile, CellBudgetFile, MfGrdFile
from flopy.utils.gridintersect import GridIntersect
try:
    import geopandas as gpd
except:
    print('PACKAGE ERROR : make sure Geopandas is installed ... (Try: pip install geopandas)')



class ParticleBuilder():
    """ 
        Particle generator utilities for modpath7 model from shapefile

    -----------
    Arguments
    -----------
    - name
    - gwf
    - g
    - shp_name
    - field_id
    -----------
    Methods
    -----------
    - get_fids()
    - gen_npart()
    - get_res_dic()
    - get_local_xy()
    - get_particle_df()
    - ...
    """
    def __init__(self, name, gwf, g = None, field_id = 'FID', shp_name = None, geometry_dic = None):
        """
        -----------
        Description
        -----------
        Constructor of ParticleBuilder() instance
        -----------
        Parameters
        -----------
        - self  (vulnerability.ParticleBuilder)
        - name  (str) : name of the ParticleBuilder instance
        - gwf   (flopy.mf6.modflow.mfgwf.ModflowGwf) : mf6 ground water flow model
        - g     (flopy.utils.gridgen.Gridgen) : flopy gridgen object
                                                Gridgen object as a way better performance to 
                                                find the list of vertices coordinates of a given
                                                cell than the built-in model grid
                                                (Default is None)
        - field_id (str) : shapefile field that contains geometry ids (Default is 'FID')
        - shp_name (str) : name of a required shapefile that contains geometries 
                           which to build particle sets (Default is None)
        - geometry_dic (dict) : geometry information into a dictionary
                                (format: { 'geom1' : shapely.geometry (Point, LineString, ..)})
                                (Default is None)
        -----------
        Returns
        -----------
        - ParticleBuilder instance
        -----------
        Examples
        -----------
        >>> pb = ParticleBuilder('WELLS', gwf, g, 'wells.shp', 'NAME')
        """
        msg = 'Geospatial object must be implemented (geometry or shp_name argument)'
        assert any(x is not None for x in [shp_name, geometry_dic]), msg
        self.name = name
        self.gwf = gwf
        self.g = g
        self.field_id = field_id
        if geometry_dic is None:
            self.shp = gpd.read_file(shp_name)
        else:
            gdf = gpd.GeoDataFrame({field_id : geometry_dic.keys()})
            self.shp = gdf.set_geometry(list(geometry_dic.values()))


    def get_fids(self):
        """
        -----------
        Description
        -----------
        Get feature names
        -----------
        Parameters
        -----------
        - self  (vulnerability.ParticleBuilder)
        -----------
        Returns
        -----------
        - fids (list) : feature names
        -----------
        Examples
        -----------
        >>> pb = ParticleBuilder('WELLS', gwf, g, 'wells.shp', 'NAME')
        >>> wells_name = pb.get_fids()
        """
        return self.shp[self.field_id].to_list()



    def gen_n_point_in_polygon(self, n_point, polygon, tol = 0.1):
        """
        -----------
        Description
        -----------
        Generate n regular spaced points within a shapely Polygon geometry
        -----------
        Parameters
        -----------
        - n_point (int) : number of points required
        - polygon (shapely.geometry.polygon.Polygon) : Polygon geometry
        - tol (float) : spacing tolerance (Default is 0.1)
        -----------
        Returns
        -----------
        - points (list) : generated point geometries
        -----------
        Examples
        -----------
        >>> geom_pts = gen_n_point_in_polygon(200, polygon)
        >>> points_gs = gpd.GeoSeries(geom_pts)
        >>> points_gs.plot()
        """
        # Get the bounds of the polygon
        minx, miny, maxx, maxy = polygon.bounds    
        # ---- Initialize spacing and point counter
        spacing = polygon.area / n_point
        point_counter = 0
        # Start while loop to find the better spacing according to tol√©rance increment
        while point_counter <= n_point:
            # --- Generate grid point coordinates
            x = np.arange(np.floor(minx), int(np.ceil(maxx)), spacing)
            y = np.arange(np.floor(miny), int(np.ceil(maxy)), spacing)
            xx, yy = np.meshgrid(x,y)
            # ----
            pts = [Point(X,Y) for X,Y in zip(xx.ravel(),yy.ravel())]
            # ---- Keep only points in polygons
            points = [pt for pt in pts if pt.within(polygon)]
            # ---- Verify number of point generated
            point_counter = len(points)
            spacing -= tol
        # ---- Return
        return points



    def gen_npart(self, dist, n_part, gen_type = 'around', tol = 0.1, fid = None, export = None):
        """
        -----------
        Description
        -----------
        Generate n regular spaced points (particles) at a given distance from shapefile geometries
        -----------
        Parameters
        -----------
        - dist (float) : distance of all generated points from a given geometry
        - n_part (int) : number of particles (points) required
        - gen_type (str) : type of particles generation. Can be 'around' or 'within'.
                           (Default is 'around')
        - tol (float) : spacing tolerance (only considered if gen_type == 'within')
                        (Default is 0.1)
        - fid (str)    : feature name (geometry) to consider (if None, all geometries are considered) 
                         Can be a single str or a list (Default is None)
        - export (str) : shapefile name to export generated points
                         (Default is None)
        -----------
        Returns
        -----------
        - sp_gdf_concat (geopandas.geodataframe.GeoDataFrame) : starting particule (point)
        -----------
        Examples
        -----------
        >>> pb = ParticleBuilder('WELLS', gwf, g, 'wells.shp', 'NAME')
        >>> well_sp = pb.gen_npart(dist = 5, n_part = 500, fid = 'WELL1')
        """
        # ---- Copy main shp and subset by feature if required
        if fid is not None:
            gdf = self.shp.loc[self.shp[self.field_id] == fid]
        else:
            gdf = self.shp.copy()
        gdf.set_index(self.field_id, inplace = True)
        sp_gdf_list = []
        # ---- Iterate over all vulnerabilities
        for feat_id in gdf.index:
            # ---- Fetch geometry
            geom = gdf.loc[feat_id,'geometry']
            # ---- Build a buffer 
            buff = geom.buffer(dist)
            # ---- Generate point around or into polygon
            if gen_type == 'around':
                # ----  Keep externe boundary as LineString object
                line = buff.boundary
                # ---- Find the distances from origin between starting points along the line
                distances = np.linspace(0, line.length,n_part)
                # ---- Create a starting point atr each distance
                sp_geom = [line.interpolate(distance) for distance in distances]
            elif gen_type == 'within':
                _sp_geom = self.gen_n_point_in_polygon(n_part, buff, tol)
                sp_geom = _sp_geom[:n_part]
            # ---- Build a GeoPandasDataFrame with points
            sp_gdf = gpd.GeoDataFrame(geometry = sp_geom)
            # ---- Build an standard ID column
            sp_gdf[self.field_id] = feat_id
            # ---- Store gdf in result dictionary
            sp_gdf_list.append(sp_gdf)
        # ---- Concatenate starting points of all feature
        sp_gdf_concat = pd.concat(sp_gdf_list, ignore_index=True)
        sp_gdf_concat.rename(columns = {self.field_id: 'FID'}, inplace = True)
        # ---- Export generated particule as shapefile
        if export is not None:
            # ---- Check if the shapefile already has a projection
            if not self.shp.crs is None:
                epsg = self.shp.crs.to_epsg()
                sp_gdf_concat.set_crs(epsg = epsg, inplace = True)
            sp_gdf_concat.to_file(export)
            print(f' Shapefile successfully wrote in {export}')
        # ---- Return result dictionary
        return(sp_gdf_concat)



    def get_res_dic(self):
        """
        -----------
        Description
        -----------
        Return dictionary of all cell resolution (square grid)
        -----------
        Parameters
        -----------
        
        -----------
        Returns
        -----------
        res_dic (dict) : dictionary of cell resolution
                         Format : {node: res}
        -----------
        Examples
        -----------
        >>> pb = ParticleBuilder('WELLS', gwf, g, 'wells.shp', 'NAME')
        >>> node = 567
        >>> res_567 = pb.get_res_dic()[nodenumber]
        """
        # ---- If Gridgen object available
        if self.g is None:
            # -- Fetch vertices coordinates
            vxs, vys, vzs = self.gwf.modelgrid.xyzvertices
            # -- Build resolution dictionary
            res_dic = {node: np.max(np.diff(vxs[node]))
                             for node in range(self.gwf.modelgrid.nnodes)}
        # ---- If Gridgen object not available
        else:
            # -- Get recarray for all nodes
            node_rec = g.get_nod_recarray()
            # -- Build resolution dictionary
            res_dic = {rec['node']: rec['dx'] for rec in node_rec}
        # ---- Return resolution dictionary
        return(res_dic)


    def get_local_xy(self, node, gx, gy, vertices=None):
        """
        -----------
        Description
        -----------
        Fetch the normalize locals x and locals y of a point define by 
        his node and global coordinates (gx, gy) into the cell
        -----------
        Parameters
        -----------
        - node (int) : Node number
        - gx (float) : Point global x-coordinates 
        - gy (float) : Point global y-coordinates
        - vertices (list) : Vertices of cell
                            Format : [(vx0, vy0), (vx1, vy1), (vx2, vy2), (vx3, vy3),(vx0, vy0)]
                            Usefull to improve eficiency if used iterativly without gridgen object 
        -----------
        Returns
        -----------
        [lx, ly] = (list) : local coordinates
        -----------
        Examples
        -----------
        >>> pb = ParticleBuilder('WELLS', gwf, g, 'wells.shp', 'NAME')
        >>> well_lx, well_ly = pb.get_local_xy(well.node, well.x, well.y)
        """
        # ---- Check if a gridgen object is available and get vertices of a given node
        if self.g is None:
            # ---- Without Gridgen utilities
            if vertices is None:
                # ---- Without specifying cell vertices (very slow process)
                vertices = self.gwf.modelgrid.get_cell_vertices(node)
        else:
            # ---- With Gridgen utilities
            vertices = self.g.get_vertices(node)
        # ---- Fetch coordinates of origin point
        vx0, vy0 = vertices[0]
        vx1, vy1 = vertices[2]
        # ---- Get resolution
        delc = vx1 - vx0
        delr = vy0 - vy1
        # ---- Calculate local corrdinates
        lx = (gx - vx0)/delc
        ly = (gy - vy1)/delr
        # ---- Return list of xy local coordinates
        return([lx, ly])


    def get_particle_df(self, dist, n_part, fid = None, export = None):
        """
        -----------
        Description
        -----------
        Generate standard DataFrame of generated points (particles) with all usefull
        informations as locs, ids, local_x, local_y to create flopy.modpath.ParticleData
        -----------
        Parameters
        -----------
        - dist (float) : distance of all generated points from a given geometry
        - n_part (int) : number of particles (points) required
        - fid (str)    : feature name (geometry) to consider (if None, all geometries are considered) 
                         Can be a single str or a list (Default is None)
        - export (str) : shapefile name to export generated points
                         (Default is None)
        -----------
        Returns
        -----------
        - sp_gdf_concat (geopandas.geodataframe.GeoDataFrame) : starting particule (point)
        -----------
        Examples
        -----------
        >>> pb = ParticleBuilder('WELLS', gwf, g, 'wells.shp', 'NAME')
        >>> well_sp = pb.gen_npart(dist = 5, n_part = 500, fid = 'WELL1')
        """
        # ---- Generate particles
        sp_gdf = self.gen_npart(dist = dist, n_part = n_part,
                                fid = fid,   export = export)
        # ---- Generate a flopy GridIntersect object
        gi = GridIntersect(self.gwf.modelgrid)
        # ---- Fetch particle grid information
        if self.g is None:
            # ---- Fetch all vertices before to improve eficiency
            vxs, vys, vzs = self.gwf.modelgrid.xyzvertices
            # ---- Iterate over all points
            for sp_id in sp_gdf.index:
                # ---- Intersect with grid 
                node, sp_vertices, sp_geom  = gi.intersect(sp_gdf.loc[sp_id,'geometry'])[0]
                # ---- Fetch vertices of node to speed up getting local coordinates
                vertices = [(vx,vy) for vx, vy in zip(vxs[node],vys[node])]
                vertices.append(vertices[0])
                # ---- Compute local coordinates
                lx, ly = self.get_local_xy(node, sp_geom.x, sp_geom.y, vertices)
                sp_gdf.loc[sp_id, ['locs', 'local_x', 'local_y']] = node, lx, ly
        else:
            # ---- Iterate over all points
            for sp_id in sp_gdf.index:
                # ---- Intersect with grid
                node, sp_vertices, sp_geom  = gi.intersect(sp_gdf.loc[sp_id,'geometry'])[0]
                # ---- Compute local coordinates
                lx, ly = self.get_local_xy(node, sp_geom.x, sp_geom.y)
                sp_gdf.loc[sp_id, ['locs', 'local_x', 'local_y']] = node, lx, ly
        # ---- Set particle ids & convert loc into integers
        sp_gdf['pid'] = np.arange(len(sp_gdf))
        sp_gdf['locs'] = sp_gdf['locs'].astype(np.int)
        # ---- Return
        particle_df = pd.DataFrame(sp_gdf.drop('geometry', axis = 1))
        return particle_df


    def __str__(self):

        print('\n')
        # ---- Collect Particle Builder main informations
        header =' MODPATH7 Particle Builder Class '
        inf =  ['Particle Builder name', 'Particle Builder field ID',
                'Particle Builder number of geometry', 'Particle Builder geometry names']
        res = [self.name, self.field_id, len(self.shp), ', '.join(self.get_fids())]
        # ---- Build DataFrame
        df = pd.DataFrame({' ': inf, header : res})
        # ---- Print table of information
        print(df.to_markdown(index = False, tablefmt="simple"))
        return '\n'


class ParticleMerger():
    """ 
        Simple wrapper tool for modpath7 simulation

    -----------
    Arguments
    -----------
    - particle_dfs
    -----------
    Methods
    -----------
    - update()
    - add()
    - remove()
    - get_particle_data()
    - get_ParticleGroup()
    """
    def __init__(self, particle_dfs = []):
        """
        -----------
        Description
        -----------
        Constructor of ParticleMerger() instance
        -----------
        Parameters
        -----------
        - self  (vulnerability.ParticleBuilder)
        - particle_dfs (list) : Dataframes from ParticleBuilder.get_particle_df() method
        -----------
        Returns
        -----------
        - ParticleBuilder instance
        -----------
        Examples
        -----------
        >>> pb = ParticleBuilder('WELLS', gwf, g, 'wells.shp', 'NAME')
        >>> wells_df = pb.get_partcile_df() 
        >>> pm = ParticleMerger([wells_dfs])
        """
        assert isinstance(particle_dfs,list), 'particle_dfs argument must be a list'
        self.particle_dfs = particle_dfs
        if particle_dfs:
            self.particle_df = pd.concat(particle_dfs, ignore_index=True)
            self.particle_df['pid'] = self.particle_df.index
        else:
            dummy_df = pd.DataFrame(columns = ['FID', 'locs', 'local_x', 'local_y', 'pid'])
            self.particle_dfs.append(dummy_df)
            self.particle_df = dummy_df

    def update(self):
        """
        -----------
        Description
        -----------
        Allows ParticleMerger instance to update particle_df from particle_dfs
        -----------
        Parameters
        -----------
        - self  (vulnerability.ParticleBuilder)
        -----------
        Returns
        -----------
        - None
        -----------
        Examples
        -----------
        >>> pb = ParticleBuilder('WELLS', gwf, g, 'wells.shp', 'NAME')
        >>> wells_df = pb.get_partcile_df() 
        >>> pm = ParticleMerger([wells_dfs])
        >>> pm.update()
        """
        self.particle_df = pd.concat(self.particle_dfs, ignore_index=True)


    def add(self, particle_df):
        """
        -----------
        Description
        -----------
        Add a new particle DataFrame
        -----------
        Parameters
        -----------
        - self  (vulnerability.ParticleBuilder)
        - particle_df (pandas.core.frame.DataFrame) : Dataframe from ParticleBuilder.get_particle_df() method
        -----------
        Returns
        -----------
        - None
        -----------
        Examples
        -----------
        >>> pb = ParticleBuilder('WELLS', gwf, g, 'wells.shp', 'NAME')
        >>> wells_df = pb.get_partcile_df() 
        >>> pm = ParticleMerger()
        >>> pm.add(wells_df)
        """
        self.particle_dfs.append(particle_df)
        self.particle_df['pid'] = self.particle_df.index
        self.update()


    def remove(self, particle_df):
        """
        -----------
        Description
        -----------
        Remove a new particle DataFrame
        -----------
        Parameters
        -----------
        - self  (vulnerability.ParticleBuilder)
        - particle_df (pandas.core.frame.DataFrame) : Dataframe from ParticleBuilder.get_particle_df() method
        -----------
        Returns
        -----------
        - None
        -----------
        Examples
        -----------
        >>> pb = ParticleBuilder('WELLS', gwf, g, 'wells.shp', 'NAME')
        >>> well1_df = pb.get_partcile_df(fid = 'WELL1')
        >>> well2_df = pb.get_partcile_df(fid = 'WELL2')
        >>> pm = ParticleMerger([well1_df, well2_df])
        >>> pm.remove(well2_df)
        """
        self.particle_dfs = [df for df in self.particle_dfs if not df.equals(particle_df)]
        self.update()


    def get_fids(self):
        """
        -----------
        Description
        -----------
        Get feature names
        -----------
        Parameters
        -----------
        - self  (vulnerability.ParticleMerger)
        -----------
        Returns
        -----------
        - fids (list) : feature names
        -----------
        Examples
        -----------
        >>> pb = ParticleBuilder('WELLS', gwf, g, 'wells.shp', 'NAME')
        >>> w1_df = pb.get_particle_df(fid = 'WELL1')
        >>> w2_df = pb.get_particle_df(fid = 'WELL2')
        >>> pm = ParticleMerger([w1_df, w2_df])
        >>> particle_groupnames = pm.get_fids()
        """
        return self.particle_df['FID'].unique().tolist()


    def get_particle_data(self, fid):
        """
        -----------
        Description
        -----------
        Get particle data of by name
        -----------
        Parameters
        -----------
        - self (vulnerability.ParticleBuilder)
        - fid  (str) : boundary name
        -----------
        Returns
        -----------
        - particle_data (list) : list of 4 elements usefull to build 
                                 flopy.modpath.ParticleData instance
                                 (format: [locs, local_x, local_y, pid])
        -----------
        Examples
        -----------
        >>> pb = ParticleBuilder('WELLS', gwf, g, 'wells.shp', 'NAME')
        >>> wells_df = pb.get_partcile_df() 
        >>> pm = ParticleMerger(wells_df)
        >>> locs, lx, ly, ids = pm.get_particle_data(fid = 'WELL1')
        """
        # ---- Subset particle_df by fid
        subset = self.particle_df[self.particle_df['FID'] == fid]
        # ---- Dop FID columns
        subset.drop('FID', axis = 1, inplace = True)
        # ---- From DataFrame to list
        particle_data = [subset[col].tolist() for col in subset.columns]
        return particle_data


    def get_ParticleGroup(self, fid, drape = 0, timeoffset = None):
        """
        -----------
        Description
        -----------
        Get flopy ParticleGroup instance
        -----------
        Parameters
        -----------
        - self (vulnerability.ParticleBuilder)
        - fid  (str) : boundary name
        - drape (int, list, tuple, np.ndarray) :
                Drape indicates how particles are treated when starting locations
                are specified for cells that are dry. If drape is 0, Particles are
                placed in the specified cell. If the cell is dry at the time of
                release, the status of the particle is set to unreleased and
                removed from the simulation. If drape is 1, particles are placed
                in the upper most active grid cell directly beneath the specified
                node location. If a single value is provided all particles will
                have the same drape value. If a list, tuple, or np.ndarray is 
                provided a drape value must be provided for each partloc.
                If drape is None, a value of 0 will be used (Default is None).
        - timeoffset (float, list, tuple, np.ndarray) :
                     Timeoffset of the particle relative to the release time. If a
                     single value is provided all particles will have the same
                     timeoffset. If a list, tuple, or np.ndarray is provided a 
                     timeoffset must be provided for each partloc. If timeoffset is
                     None, a value of 0. (equal to the release time) will be used
                     (Default is None)
        -----------
        Returns
        -----------
        - pg (flopy.modpath.mp7particlegroup.ParticleGroup)
        -----------
        Examples
        -----------
        >>> pb = ParticleBuilder('WELLS', gwf, g, 'wells.shp', 'NAME')
        >>> wells_df = pb.get_partcile_df() 
        >>> pm = ParticleMerger(wells_df)
        >>> pg1 = pm.get_ParticleGroup(fid = 'WELL1')
        """
        # ---- Get particle data
        locs, lx, ly, pid = self.get_particle_data(fid)
        # ---- Build ParticleData
        pdata = ParticleData(partlocs = locs, structured=False,
                             timeoffset = timeoffset, drape=drape,
                             localx=lx, localy=ly, particleids = pid)
        # ---- Get ParticleGroup
        pg = ParticleGroup(particlegroupname= fid, particledata=pdata)
        # ---- Return
        return pg





class SSRV():
    """ 
        Class to define river vulnerability object from a backward 
        steady-state particle tracking 

    -----------
    Arguments
    -----------
    - gwf
    - mpsim
    -----------
    Methods
    -----------
    - get_reach_names()
    - get_reach_dic()
    - agg_reach_by_name()
    - get_cell_amount()
    - get_icell_flows()
    - compute_mixing_ratio()
    """
    
    def __init__(self, gwf, mpsim, precision = 'double'):
      """
      -----------
      Description
      -----------
      Constructor of SSRV instance
      (NOTE: only available for steady-state simulation on
             DISV spatial discretization with backward particle tracking)
      -----------
      Parameters
      -----------
      - self  (vulnerability.SSRV)
      - gwf   (flopy.mf6.modflow.mfgwf.ModflowGwf) : mf6 ground water flow model
      - mpsim (flopy.modpath.mp7sim.Modpath7Sim) : mp7 simulation
      - precision (str) : precision of the floating point data of the cbc file
                          Can be 'simple' or 'double'
                          (Default is 'double')
      -----------
      Returns
      -----------
      - SSRR instance
      -----------
      Examples
      -----------
      >>> ssrv = SSRV(gwf, mpsim)
      """
      # ---- Bunch of assertion to raise
      # Assuming that the model is steady-stade
      assert gwf.nper == 1, 'The flow model must be in steady-state conditions'
      # Assuming that the model spatial dscretisation is DISV like
      assert gwf.get_grid_type().name == 'DISV', 'The spatial discretisation must be DISV like'
      # ---- Assuming that the groudwater flow model contain RIV package
      assert gwf.get_package('RIV'), 'The flow model does not contains river condition'
      # ---- Assuming that each river cell contains a boundanme (reach name)
      msg = 'boundnames must be specified for each river cells in RIV stress period data'
      boundnames = gwf.get_package('RIV').stress_period_data.get_data(0)['boundname']
      assert all([x is not None for x in boundnames]), msg
      # ---- Assuming that the particle tracking is backward oriented
      assert mpsim.trackingdirection == 2, 'The Particle tracking has to be backward'
      # ---- Define flow and transport models
      self.gwf = gwf
      self.mpsim = mpsim
      # ---- Fetch cbc file 
      cbc_name = ''.join(gwf.get_package('OC').budget_filerecord.get_data().budgetfile)
      self.cbc = CellBudgetFile(os.path.join(gwf.model_ws, cbc_name), precision = precision)
      # ---- Fetch endpoint file
      self.edp = EndpointFile(os.path.join(gwf.model_ws, mpsim.endpointfilename))
      # ---- Fetch pathline file
      self.pth = PathlineFile(os.path.join(gwf.model_ws, mpsim.pathlinefilename))
      # ---- Build equivalence between particle group name / particle group numeric id
      self.part_group_ids_num = {pg.particlegroupname: pg_id for pg_id, pg in enumerate(mpsim.particlegroups)}
      # ---- Fetch river leakage data as data frame, fixing 1-based cbc file issue
      river_leakage = self.cbc.get_data(text='RIV')[0]
      self.river_leakage_df = pd.DataFrame( {'node':river_leakage['node']-1,
                                             'q':river_leakage['q']} ).set_index('node')
      # ---- Fetch cell conectivity (FLOW-JA-FACE)
      self.flowja = gwf.simulation_data.mfdata[gwf.name, 'CBC', 'FLOW-JA-FACE'][0][0, 0, :]
      # ---- Fetch IA information from binary grid file
      bgf = MfGrdFile(os.path.join(gwf.model_ws,
                                   '{}.{}.grb'.format(gwf.name,
                                                      gwf.get_grid_type().name.lower())))
      self.ia = bgf._datadict['IA'] - 1


    def get_reach_names(self):
      """
      -----------
      Description
      -----------
      Get list of river reach names from 'RIV' packages
      -----------
      Parameters
      -----------
      - self (vulnerability.SSRV)
      -----------
      Returns
      -----------
      - boundnames (list) : river reaches
      -----------
      Examples
      -----------
      >>> ssrv = SSRV(gwf, mpsim)
      >>> reach_names = ssrv.get_reach_names()
      """
      # ---- Fetch rech names from river package (boundnames)
      rec = self.gwf.get_package('RIV').stress_period_data.get_data(0)
      boundnames = list(set(rec['boundname']))
      # ---- Return
      return boundnames


    def get_reach_dic(self):
      """
      -----------
      Description
      -----------
      Get river nodes for every reach
      (NOTE: 'RIV' package must contains boundname for each river cell)
      -----------
      Parameters
      -----------
      - self (vulnerability.SSRV)
      -----------
      Returns
      -----------
      - reach_dic (dict) : reach dictionary
      -----------
      Examples
      -----------
      >>> ssrv = SSRV(gwf, mpsim)
      >>> reach_dic = ssrv.get_reach_dic()
      """
      # ---- Fetch rech names from river package (boundnames)
      rec = self.gwf.get_package('RIV').stress_period_data.get_data(0)
      # ---- Build standard reaches dictionnary from river package
      reach_dic = {k:[] for k in set(rec['boundname'])}
      for boundname in reach_dic.keys():
        cellids = rec[rec['boundname'] == boundname]['cellid']
        for cellid in cellids:
          reach_dic[boundname].append(cellid[1])
      # ---- return
      return reach_dic



    def agg_reach_by_name(self, agg_dic):
      """
      -----------
      Description
      -----------
      Aggregate river reaches by their name
      (NOTE: 'RIV' package must contains boundname for each river cell)
      -----------
      Parameters
      -----------
      - self (vulnerability.SSRV)
      - agg_dic (dict) : Aggregation dictionary infos 
                         (format: {'reach_group1' : ['reach1', 'reach2', 'reach3'],
                                   'reach_group2' : ['reach4', 'reach5']} )
      -----------
      Returns
      -----------
      - agg_reach_dic (dict) : new reach dictionary
      -----------
      Examples
      -----------
      >>> ssrv = SSRV(gwf, mpsim)
      >>> agg_reach_dic = ssrv.agg_reach_by_name({'Amazone' : ['AM1', 'AM2', 'AM3'],'East_Amazone' : ['EA1', 'EA2']})
      """
      # ---- Get all reaches
      reach_dic = self.get_reach_dic()
      agg_reach_dic = {}
      for agg_reach, reaches in agg_dic.items():
        agg_reach_dic[agg_reach] = [*[nodes for reach in reaches 
                                            for nodes in reach_dic[reach]]]
      # ---- Return
      return agg_reach_dic



    def get_cell_amount(self, agg_dic = None, verbose = False):
        """
        -----------
        Description
         -----------
        Get number of river cells for each reach of
         -----------
        Parameters
        -----------
        - self (vulnerability.SSRV)
        - agg_dic (dict) : Aggregation dictionary infos 
                           (format: {'reach_group1' : ['reach1', 'reach2', 'reach3'],
                                   'reach_group2' : ['reach4', 'reach5']} )
                            (Default is None)
        - verbose (bool) : Print river's cell amount in console
                           (Default is False)
        -----------
        Returns
        -----------
        - ca (dict) : cell amount of each river reach
        -----------
        Examples
        -----------
        >>> ssrv = SSRV(gwf, mpsim)
        >>> ca = ssrv.get_cell_amont(verbose = True)
        """

        # ---- Checkout aggregation dict
        if agg_dic is not None:
            ca = {reach: len(nodes) for reach, nodes in  self.agg_reach_by_name(agg_dic).items()}
        else:
            ca = {reach: len(nodes) for reach, nodes in  self.get_reach_dic().items()}

        # ---- Print results if required
        if verbose:
            df = pd.DataFrame({'Reach': ca.keys(), 'Amount of cells': ca.values()})
            print(df.to_markdown(index=False, tablefmt="simple"))

        # Return cell amount dict
        return ca



    def get_icell_flows(self, node):
      """
      -----------
      Description
      -----------
      Compute intercells flows budget of a specific grid cell
      Boundary conditions not included (well,  ..)
      -----------
      Parameters
      -----------
      - self (vulnerability.SSRV)
      - node (int) : node number of the cell
      -----------
      Returns
      -----------
      Cell budget
      -----------
      Examples
      -----------
      >>> ssrv = SSRV(gwf, mpsim)
      >>> cb_11325 = ssrv.get_icell_budget(11325)
      """
      flows = []
      for ipos in range(self.ia[node]+1, self.ia[node+1]):
          flows.append( self.flowja[ipos])
      return(flows)


    # ---- Compute mixing ratios
    
    def compute_mixing_ratio(self, agg_dic = None, filled = False):
      """
      -----------
      Description
      -----------
      Compute the mixing ratio between river water and ground water at a 
      given water production puit
      -----------
      Parameters
      -----------
      - self (vulnerability.SSRV)
      - agg_reach_dic (dict) : aggregated reaches names
                               (format: {'reach_group1' : ['reach1', 'reach2', 'reach3'],
                                   'reach_group2' : ['reach4', 'reach5']} )
                               (Default is None)
      - filled (bool) : fill mixing ratio with ground water apportation
                        (Default is False)
      -----------
      Returns
      -----------
      - mr_df (pandas.core.frame.DataFrame) : results of mixing ratio calculation

      -----------
      Examples
      -----------
      >>> ssrv = SSRV(gwf, mpsim)
      >>> mr_df = ssrv.compute_mixing_ratio(filled = True)
      """
      # ---------------> STEP 1 <---------------
      # ---- Get reach dictionary
      if agg_dic is None:
        reach_dic = self.get_reach_dic()
      else:
        reach_dic = self.agg_reach_by_name(agg_dic)
      # ---------------> STEP 2 <---------------
      # ---- Compute river contribution for all particule that terminate in river cell
      # ---- Keep only river endpoints
      all_river_nodes = [node for nodes in reach_dic.values() for node in nodes]
      edp_df = pd.DataFrame(self.edp.get_alldata())
      riv_edp_df = edp_df.query(f'node in {all_river_nodes}')
      # ---- iterate over each particle termininating in river
      for part_id in riv_edp_df.index:
        # ---- Fetch node particles endpoint
        riv_node = riv_edp_df.loc[part_id,'node']
        # ---- Fetch river leakage at this node
        riv_leak = self.river_leakage_df.loc[riv_node,'q']
        # ---- Fetch total inflows in this node
        icell_flows = self.get_icell_flows(riv_node)
        icell_inflows = np.array([ flow for flow in icell_flows if flow > 0]).sum()
        # ---- Compute infdividual mixing ratio
        alpha_i = riv_leak / (riv_leak + icell_inflows)
        riv_edp_df.loc[part_id,'alpha_i'] = alpha_i
        # ---- Compute particle velocity
        rec = self.pth.get_data(part_id)
        try:
          t0_data, t1_data = rec[rec['time'] > 1][:2]
          dt = t1_data['time'] - t0_data['time']
          dist = np.sqrt((t0_data['x'] - t1_data['x'])**2 + (t0_data['y'] - t1_data['y'])**2)
          vi = dist/dt
        except:
          vi = 0
        riv_edp_df.loc[part_id,'vi'] = vi
        # ---- Add column with river source name for each endpoint
        for riv_id, riv_nodes in reach_dic.items():
          if riv_node in riv_nodes:
            riv_edp_df.loc[part_id, 'riv_id'] = riv_id

      # ---- Compute river contribution (mixing ratio * velocity)
      riv_edp_df['river_contri'] = riv_edp_df['alpha_i'] * riv_edp_df['vi']
      # ---------------> STEP 3 <---------------
      # ---- Compute total mixing ratio as sum(alpha_i * vi)/ sum(vi)
      # ---- Initialize empty mixing ratio dictionnary
      alpha_dic = {}
      # ---- Iterate over all production points (particle groups)
      for part_gpnme, part_gpid in self.part_group_ids_num.items():
        # ---- Subset endpoint DataFrame by particle group numeric id
        part_gp_df = riv_edp_df.query(f'particlegroup == {part_gpid}')
        # ---- Save the sum of velocity of each particle
        vi_sum = part_gp_df.vi.sum()
        # ---- Aggregate particle group Dataframe by river contribution sum
        riv_grouby = part_gp_df.groupby('riv_id').sum().river_contri
        # ---- Compute mixing ratio for each river source
        riv_mr = riv_grouby / vi_sum
        # ---- Complete mixing ratio dictionnary with results ( alpha set to 0 if none particles is from a inputed section of river)
        alpha_dic[part_gpnme] = { riv_id : riv_mr.loc[riv_id] 
                                  if riv_id in riv_mr.index 
                                  else 0. 
                                  for riv_id in reach_dic.keys()}

      # ---- Convert alpha_dic to Dataframe
      mr_df = pd.DataFrame(alpha_dic).T

      # ---- Complete mixing ratio with other naturals apportation 
      if filled:
        mr_df['ground_water'] = 1 - mr_df.sum(axis = 1)
      # ---- Set meaningful headers
      mr_df.columns = [f'from_{col}' for col in mr_df.columns]
      # ---- Return
      return mr_df



    def __str__(self):

        print('\n')
        # ---- Print head
        header = ' Steady-State River Vulnerability Class '
        # ---- Collect SSRV main informations
        inf =  ['Ground Water Flow model', 'Number of river reaches',
                'Names of river reaches', 'Particle Group names',
                'Particle Group ids']
        res = [self.gwf.name, len(self.get_reach_names()), 
               ', '.join(sorted(self.get_reach_names())),
               ', '.join(list(self.part_group_ids_num.keys())),
               ', '.join([str(i) for i in self.part_group_ids_num.values()])]
        # ---- Build DataFrame
        df = pd.DataFrame({' ': inf, header : res})
        # ---- Print table of information
        print(df.to_markdown(index = False, tablefmt="simple"))
        return '\n'




class SSZV():
    """ 
        Class to define zonal vulnerability object from a backward 
        steady-state particle tracking 

    -----------
    Arguments
    -----------
    - gwf
    - mpsim
    - field_id
    - shp_name
    - geometry_dic
    -----------
    Methods
    -----------
    - get_fids()
    - numbool2percent()
    - get_zonal_vulnerability()
    - get_methods()
    - get_pvelocity()
    - get_numbool()
    - plot_venn()
    """
    
    def __init__(self, gwf, mpsim, field_id = 'FID', shp_name = None, geometry_dic = None):
      """
      -----------
      Description
      -----------
      Constructor of SSZV instance
      (NOTE: only available for steady-state simulation on
             DISV spatial discretization with backward particle tracking)
      -----------
      Parameters
      -----------
      - self  (vulnerability.SSZV)
      - gwf   (flopy.mf6.modflow.mfgwf.ModflowGwf) : mf6 ground water flow model
      - mpsim (flopy.modpath.mp7sim.Modpath7Sim) : mp7 simulation 
      - field_id (str) : shapefile field that contains geometry ids
                         (Default is 'FID')
      - shp_name (str) : name of a required shapefile that contains polygon geometries
                         (Default is None)
      - geometry_dic (dict) : geometry information into a dictionary
                              (format: { 'geom1' : shapely.geometry.Polygon})
                              (Default is None)
      -----------
      Returns
      -----------
      - SSZV instance
      -----------
      Examples
      -----------
      >>> sszv = SSZV(gwf, mpsim, field_id = 'ID', shp_name = 'valnerabilities.shp')
      """
      # ---- Bunch of assertion to raise
      # Assuming that the model is steady-stade
      assert gwf.nper == 1, 'The flow model must be steady-state like'
      # Assuming that the model spatial dscretisation is DISV like
      assert gwf.get_grid_type().name == 'DISV', 'The spatial discretisation must be DISV like'
      # Assuming that the particle tracking is backward oriented
      assert mpsim.trackingdirection == 2, 'The Particle tracking is not set as backward'
      # Assuming that at least one geospatial object (zone) is implemented
      msg = 'Geospatial object (zone polygon) must be implemented (geometry or shp_name argument)'
      assert any(x is not None for x in [shp_name, geometry_dic]), msg

      # ---- Define flow and transport models
      self.gwf = gwf
      self.mpsim = mpsim

      # ---- Fetch zones from shapefile or geometry
      self.field_id = field_id

      if geometry_dic is None:
        self.vul_zone = gpd.read_file(shp_name)
      else:
        gdf = gpd.GeoDataFrame({field_id : geometry_dic.keys()})
        self.vul_zone = gdf.set_geometry(list(geometry_dic.values()))
         

      # ---- Build Pathlines GeoDataFrame
      # 1) Get endpoint data
      edp  = EndpointFile(os.path.join(gwf.model_ws, mpsim.endpointfilename))
      edp_df = pd.DataFrame(edp.get_alldata()).set_index('particleid')
      self.edp = edp

      # 2) Get pathline data
      pth = PathlineFile(os.path.join(gwf.model_ws, mpsim.pathlinefilename))
      pth_df = pd.concat([pd.DataFrame(rec) for rec in pth.get_alldata()])
      self.pth = pth

      # 3) Convert points to lines
      pth_points = gpd.GeoDataFrame(pth_df, geometry = gpd.points_from_xy(pth_df.x, pth_df.y))
      pth_lines = pth_points.groupby(['particleid'])['geometry'].apply(lambda p: LineString(p.tolist()))

      self.pth_gdf = pth_lines.to_frame().merge(edp_df, left_index = True, right_index = True)

      # ---- Build equivalence between particle group name / particle group numeric id
      self.part_group_ids_num = {pg.particlegroupname: pg_id for pg_id, pg in enumerate(mpsim.particlegroups)}




    def numbool2percent(self, df, columns, groupby_col = None):
        """
        -----------
        Description
        -----------
        Transform numerical boolean columns of a DataFrame in percent
        -----------
        Parameters
        -----------
        - df (pandas.core.frame.DataFrame) : original DataFrame that contains boolean columns
        - columns (list) : required boolean columns
        - groupby_col (str) : column name to group data before computing percent if required
                              (Default is None)
        -----------
        Returns
        -----------
        res (pandas.core.frame.DataFrame) : resulting percent DataFrame
        -----------
        Examples
        -----------
        >>> data = {col_id: np.random.randint(2, size=200) for col_id in list('abcdefg')}
        >>> df = pd.DataFrame(data)
        >>> percent_df = numbool2percent(df = df, columns = df.columns) * 100
        """
        if groupby_col is None:
            # ---- Compute pourcent on all DataFrame
            res = pd.DataFrame(df[columns].apply(sum, axis = 0) / len(df)).T
        else:
            # ---- Group by groupby_col with count and sum statistics
            stat_df = df.groupby(groupby_col)[columns].agg(['sum', 'count'])
            # ---- Switch from MultIndex to SimpleIndex
            stat_df.columns = ['_'.join(col).strip() for col in stat_df.columns.values]
            # ---- Compute percent as sum/count
            for col in columns: stat_df[col] = (stat_df[col + '_sum'] / stat_df[col + '_count'])
            # ---- Drop useless columns
            res = stat_df.drop(stat_df.columns[stat_df.columns.str.endswith(('_sum', '_count'))], axis = 1)
        # ---- Return 
        return(res)



    def get_fids(self):
        """
        -----------
        Description
        -----------
        Get feature names
        -----------
        Parameters
        -----------
        - self  (vulnerability.SSZV)
        -----------
        Returns
        -----------
        - fids (list) : feature names
        -----------
        Examples
        -----------
        >>> sszv = SSZV(gwf, 'vulnerable_zones.shp', field_id = 'NAME')
        >>> zone_names = sszv.get_fids()
        """
        return self.vul_zone[self.field_id].to_list()



    def get_methods(self):
        """
        -----------
        Description
        -----------
        Get particle pathline intersection methods
        -----------
        Parameters
        -----------
        - self  (vulnerability.SSZV)
        -----------
        Returns
        -----------
        - methods (list) : list of methods to consider intersection between particle 
                           pathlines and vulnerability zones
        -----------
        Examples
        -----------
        >>> sszv = SSZV(gwf, 'vulnerable_zones.shp', field_id = 'NAME')
        >>> methods = sszv.get_methods()
        """
        return ['all', 'first', 'last']



    def get_pvelocity(self, part_id):
        """
        -----------
        Description
        -----------
        Compute particle velocity
        -----------
        Parameters
        -----------
        - self  (vulnerability.SSZV)
        - part_id (int) : id of a given particle
        -----------
        Returns
        -----------
        - vi (float) : particle arriving velocity 
        -----------
        Examples
        -----------
        >>> sszv = SSZV(gwf, 'vulnerable_zones.shp', field_id = 'NAME')
        >>> vi = sszv.get_pvelocity(part_id = 1)
        """
        # ---- Get particle data
        rec = self.pth.get_data(part_id)
        # ---- Extract time > 1 sec
        t0_data, t1_data = rec[rec.time > 1][:2]
        # ---- Get dt (time between 2 positional points)
        dt = t1_data.time - t0_data.time
        # ---- Get distance between points
        #dist = Point(t0_data.x, t0_data.y).distance(Point(t1_data.x,t1_data.y))
        dist = np.sqrt((t0_data.x - t1_data.x)**2 + (t0_data.y - t1_data.y)**2)
        vi = dist/dt
        # Return
        return vi


    def get_numbool(self, method = 'all'):
        """
        -----------
        Description
        -----------
        Compute numeric boolean mask from particle pathline intersection
        -----------
        Parameters
        -----------
        - self  (vulnerability.SSZV)
        - method (str) : intersection whith vulnerability zone to keep 
                         to compute zonal vulnerability
                         (Default is 'all')
                         Can be
                            - 'all' : consider all zones of vulnerability intersected
                            - 'first' : consider only the first zone of vulnerability intersected
                            - 'last' : consider only the last zone of vulnerability intersected 
        -----------
        Returns
        -----------
        - pth_gdf (pandas.core.frame.GeoDataFrame) : intersection numerix boolean DataFrame
                                                     extended with pathline data
        - zlabels (set) : set of all zones or zone groups intersected
        -----------
        Examples
        -----------
        >>> sszv = SSZV(gwf, 'vulnerable_zones.shp', field_id = 'NAME')
        >>> zlabels, numbool = sszv.get_numbool()
        """
        # ---- Create a copy of pathline GeoDataFrame
        pth_gdf = self.pth_gdf.copy()
        if not self.vul_zone.crs is None:
            pth_gdf.set_crs(epsg = self.vul_zone.crs.to_epsg(), inplace = True)

        # ---- Intersect pathline with vulnerability zone
        inter_gdf = gpd.sjoin(pth_gdf, self.vul_zone, how = 'left', op = 'intersects')
        # ---- Add GroundWater origin
        inter_gdf[self.field_id].fillna('GW', inplace =True)

        # ---- Get list of vulnerability zones intersected
        groupby = inter_gdf[self.field_id].groupby('particleid')
        inter_vul_ids = groupby.apply(lambda x: ' & '.join([str(f) for f in x]))

        # ---- Get all groups of intersected zones
        zlabels = set(inter_vul_ids)

        # ---- Build numeric boolean mask accoding to the choosen method
        for zlabel in zlabels:
            if method == 'all':
                pth_gdf[zlabel] = [1 if zlabel in inter_vuls else 0 for inter_vuls in inter_vul_ids]
            elif method == 'first':
                pth_gdf[zlabel] = [1 if zlabel == inter_vuls.split(' & ')[0] else 0 for inter_vuls in inter_vul_ids]
            elif method == 'last':
                pth_gdf[zlabel] = [1 if zlabel == inter_vuls.split(' & ')[-1] else 0 for inter_vuls in inter_vul_ids]
            else:
                err_msg = f" - INVALID METHOD - \n Method must be 'all', 'first' or 'last'. Given : '{method}'"
                raise ValueError(err_msg)

        # ---- return numeric boolean mask (as DataFrame)
        
        return zlabels, pth_gdf


    
    def compute_zonal_vulnerability(self, method = 'all', pond_velocity = True):
        """
        -----------
        Description
        -----------
        Compute zonal vulnerability from MODPATH7 backward particle tracking
        -----------
        Parameters
        -----------
        - self  (vulnerability.SSZV)
        - method (str) : intersection whith vulnerability zone to keep 
                         to compute zonal vulnerability
                         (Default is 'all')
                         Can be
                            - 'all' : consider all zones of vulnerability intersected
                            - 'first' : consider only the first zone of vulnerability intersected
                            - 'last' : consider only the last zone of vulnerability intersected
        - pond_velocity (bool) : ponderate particle by arrival velocity at vulnerable zone
                                 (Default is True)
        -----------
        Returns
        -----------
        - zv_df (pandas.core.frame.DataFrame) : % of water that comes from each vulnerable zone
        -----------
        Examples
        -----------
        >>> sszv = SSZV(gwf, 'vulnerable_zones.shp', field_id = 'NAME')
        >>> zv_df = sszv.compute_zonal_vulnerability(filled = True)
        """
        # ---- Get numeric boolean mask of particle pathline intersection with vulnerability zones
        zlabels, pth_gdf = self.get_numbool(method = method)

        # ---- Add velocity ponderation
        if pond_velocity:
            # ---- Get particles velocity
            pth_gdf['vi'] = [self.get_pvelocity(part_id) for part_id in self.pth_gdf.index]
            # ---- Compute contribution by performing numeric boolean mask * velocity
            contri_df = pth_gdf[zlabels].multiply(pth_gdf['vi'], axis = 0)
            # ---- Change columns names
            contri_df.columns = [f'{vul_id}_contri' for vul_id in contri_df.columns]
            # ---- Join numeric boolean DataFrame with contribution & group by particlegroup
            gb_df = pth_gdf.join(contri_df, how='outer').groupby('particlegroup').sum()
            # -- Compute zonal vulnerability as sum(contribution) / sum(vi)
            zv = {vul_id : gb_df[f'{vul_id}_contri'].div(gb_df.vi).values for vul_id in zlabels}
            # ---- Convert to DataFrame
            zv_df = pd.DataFrame(zv)
        else:
            # ---- Convert GeoDataFrame in regular DataFrame
            pth_df = pd.DataFrame(pth_gdf.drop('geometry', axis = 1))
            # ---- Convert numeric boolean intersection into % of zonal origin particles
            zv_df = self.numbool2percent(df = pth_df, columns = list(zlabels), groupby_col = 'particlegroup')
            # ---- Complete mixing ratio with other naturals apportation
            zv_df['GW'] = 1 - zv_df.sum(axis = 1)

        # ---- Convert particle group ids into particle group names
        zv_df.index = self.part_group_ids_num.keys()
        # ---- Set meaningful headers
        zv_df.columns = [f'from {col}' for col in zv_df.columns]

        # ---- Return
        if method == 'all':
            return zv_df
        else:
            return zv_df[[col for col in zv_df.columns if not ' & ' in col]]



    def plot_venn(self, pg, colors = None, export = None, **kwargs):
        """
        -----------
        Description
        -----------
        Plot Venn diagram from particle intersection with vulnerability zones
        -----------
        Parameters
        -----------
        - self  (vulnerability.SSZV)
        - pg (int/str) : particle group name (str) or particle group id (int) to plot
        - colors (list) : colors of venn circles
                          (Default is None)
        - export (str, optional) : filename of output plot if required
                                   (Default is None)
        - **kwargs : keyword arguments for venn circle such as ls, lw, alpha, color, ..
        -----------
        Returns
        -----------
        - ax (matplotlib.axes._subplots.AxesSubplot) : axe of Venn diagram
        - v (matplotlib_venn._common.VennDiagram) : venn2 or venn3 object
        - c (list) : list of matplotlib.patches.Circle that define Venn diagram
        -----------
        Examples
        -----------
        >>> self = sszv(gwf, 'vulnerable_zones.shp', field_id = 'NAME')
        >>> ax, v, c = sszv.plot_venn('WELL1', colors = ['red', 'green', 'blue'], circle_ls = ':')
        """

        # ---- Make sure that plotting Venn Diagram is possible (Only 2 and 3 sets available)
        msg = f'Venn plot are available only for 2 or 3 vulnerability zones \n Given {len(self.vul_zone)}'
        assert len(self.vul_zone) in [2, 3] , msg

        # ---- Create a copy of pathline GeoDataFrame
        pth_gdf = self.pth_gdf.copy()
        if not self.vul_zone.crs is None:
            pth_gdf.set_crs(epsg = self.vul_zone.crs.to_epsg(), inplace = True)

        # ---- Intersect pathline with vulnerability zone
        inter_gdf = gpd.sjoin(pth_gdf, self.vul_zone, how = 'left', op = 'intersects')

        # ---- Convert intersected zone serie into DataFrame
        if isinstance(pg, str):
            pg_num_id = self.part_group_ids_num[pg]
        else:
            pg_num_id = pg

        df = inter_gdf.loc[pth_gdf.particlegroup == pg_num_id, self.field_id].to_frame()

        # ---- Extract number total of particle
        npart = len(set(df.index))

        # ---- Copy index in a new column
        df['pid'] = df.index
        # ---- Group by vulnerability zone to get venn sets
        venn_dic = df.groupby(self.field_id)['pid'].apply(set).to_dict()
        # ---- Plot Venn diagram

        # -- Prepare plot
        plt.rc('font', family='serif', size=9)
        fig = plt.figure(figsize=(10, 10))
        ax = fig.add_subplot(1, 1, 1)

        # -- Set colors to rgba
        if not colors is None:
            if len(colors) == len(self.vul_zone):
                ccolors =  [mpl.colors.to_rgba(c) for c in colors]
            else:
                raise Exception(f'Invalid number of colors: expected {len(self.vul_zone)}')
        else:
            ccolors = plt.cm.Accent(np.arange(len(self.vul_zone)))

        # -- Plot Venn for 3 sets
        if len(self.vul_zone) == 2:
            v = venn2(subsets = venn_dic.values(),
                      set_labels = venn_dic.keys(),
                      set_colors = ccolors, ax= ax)
            # -- Modify labels colors and opacity
            for lid, color in zip(['A', 'B', 'C'], ccolors):
                v.get_label_by_id(lid).set_color(color)
            # --- Modify circle line
            c = venn2_circles(venn_dic.values(), **kwargs)

        # -- Plot Venn for 3 sets
        elif len(self.vul_zone) == 3:
            v = venn3(subsets = venn_dic.values(),
                      set_labels = venn_dic.keys(),
                      set_colors = ccolors, ax= ax)
            # -- Modify labels colors and opacity
            for lid, color in zip(['A', 'B', 'C'], ccolors):
                v.get_label_by_id(lid).set_color(color)
            # --- Modify circle line
            c = venn3_circles(venn_dic.values(), **kwargs)

        # ---- Add number total of particle and particle group name
        pg_name = list(self.part_group_ids_num.keys())[list(self.part_group_ids_num.values()).index(pg_num_id)]
        text = f'Particle group n¬∞ {pg_num_id} : {pg_name} \n Number total of particle : {npart}'
        ax.text(0.8, 0.9, text, fontsize = 8.5, ha = 'center', va ='center', transform = ax.transAxes)

        # ---- Export plot if required
        if export is not None:
            fig.savefig(export, dpi = 400)

        # ---- Return
        return ax, v, c



    def __str__(self):

        print('\n')
        # ---- Print head
        header = ' Steady-State Zonal Vulnerability Class '
        # ---- Collect SSRV main informations
        inf =  ['Number of vulnerability zones', 'Names of vulnerability zones',
                'Particle Group names', 'Particle Group ids']
        res = [len(self.vul_zone), ', '.join(sorted(self.get_fids())),
               ', '.join(list(self.part_group_ids_num.keys())),
                ', '.join([str(i) for i in self.part_group_ids_num.values()])]
        # ---- Build DataFrame
        df = pd.DataFrame({' ': inf, header : res})
        # ---- Print table of information
        print(df.to_markdown(index = False, tablefmt="simple"))
        return '\n'

